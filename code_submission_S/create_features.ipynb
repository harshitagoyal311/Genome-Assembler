{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import json \n",
      "import os \n",
      "from Bio import SeqIO\n",
      "import urllib2 \n",
      "import sys\n",
      "import ast\n",
      "import numpy as np  \n",
      "import statistics\n",
      "import math\n",
      "import xlsxwriter\n",
      "import numpy as np\n",
      "from sklearn.decomposition import PCA\n",
      "from sklearn.cluster import KMeans, MeanShift,Birch\n",
      "from sklearn.cluster import AgglomerativeClustering\n",
      "from Bio import pairwise2\n",
      "import pandas as pd\n",
      "import subprocess\n",
      "\n",
      "\n",
      "import time\n",
      "start_time = time.time()\n",
      "\n",
      "PATH='./data/features/'\n",
      "\n",
      "\n",
      "\n",
      "#Contig length\n",
      "def length(contigs):\n",
      "\t\n",
      "\tcontig_length = []  \n",
      "\tfor item in contigs:\n",
      "\t\tcontig_length.append(len(contigs[item]))\n",
      "\n",
      "\treturn contig_length \n",
      "\n",
      "\n",
      "#Average contig length\n",
      "def average_contig_length(contigs):\n",
      "\t\n",
      "\ttotal_contig_length = length(contigs)\n",
      "\ttotal_contig_sum = sum(total_contig_length)\n",
      "\taverage_contig_len = total_contig_sum / len(total_contig_length)\n",
      "\n",
      "\treturn average_contig_len \n",
      "\n",
      "\n",
      "\n",
      "# Number of reads & average read length \n",
      "def read_information(file_name):\n",
      "\tcount = 0 \n",
      "\ttotal_read_length = 0\n",
      "\tfor seq_record in SeqIO.parse(file_name,\"fasta\"):\n",
      "\t\tcount = count + 1 \n",
      "\t\ttotal_read_length = total_read_length + len(seq_record.seq)\n",
      "\n",
      "\taverage_read_length = total_read_length / count \n",
      "\n",
      "\treturn_list = []\n",
      "\n",
      "\treturn_list.append(count)\n",
      "\treturn_list.append(average_read_length)\n",
      "\n",
      "\treturn return_list\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "def N50(contigs):\n",
      "\tcontig_length_list = length(contigs)\n",
      "\ttotal_length = sum(contig_length_list)\n",
      "\tinspect_length = total_length * 0.5 \n",
      "\t#Sorted list of contigs\n",
      "\tsorted_contig_length_list = sorted(contig_length_list,reverse=True)\n",
      "\n",
      "\ttemp_sum = 0 \n",
      "\t#Loop to find the least item among the contig set which makes upto 50% of the contig lengths\n",
      "\tfor item in sorted_contig_length_list:\n",
      "\t\ttemp_sum += item \n",
      "\t\tif temp_sum >= inspect_length:\n",
      "\t\t\tanswer = item \n",
      "\t\t\tbreak \n",
      "\treturn answer \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "def N90(contigs):\n",
      "\tcontig_length_list = length(contigs)\n",
      "\ttotal_length = sum(contig_length_list)\n",
      "\tinspect_length = total_length * 0.9 \n",
      "\tsorted_contig_length_list = sorted(contig_length_list,reverse=True)\n",
      "\n",
      "\ttemp_sum = 0 \n",
      "\tfor item in sorted_contig_length_list:\n",
      "\t\ttemp_sum += item \n",
      "\t\tif temp_sum >= inspect_length:\n",
      "\t\t\tanswer = item \n",
      "\t\t\tbreak \n",
      "\n",
      "\n",
      "\treturn answer \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "def L50(contigs):\n",
      "\n",
      "\tN50_measurement = N50(contigs)\n",
      "\tcontig_length_list = length(contigs)\n",
      "\tindex = contig_length_list.index(N50_measurement) + 1 \n",
      "\n",
      "\treturn index\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "#Coverage ( G: Actual Genome Size )\n",
      "def coverage(G,name):\n",
      "\t#Coverage = no.of reads*av. read length / original genome length\n",
      "\tcore_coverage = (read_information(name)[0] * read_information(name)[1]) / G \n",
      "\n",
      "\treturn core_coverage \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "def GC_content(contigs):\n",
      "\tGC_count =0\n",
      "\tfor item in contigs:\n",
      "\t\tif 'G' in item: \n",
      "\t\t\tGC_count+=1\n",
      "\t\tif 'C' in item: \n",
      "\t\t\tGC_count+= 1\n",
      "\tGC_count = float((GC_count/total)*100)\n",
      "\treturn GC_count\n",
      "\t\n",
      "\t\n",
      "\n",
      "\n",
      "\n",
      "def N50_feature(contigs):\n",
      "\tN50_feature_set = []\n",
      "\tN50_value = N50(contigs)\n",
      "\tcontig_length_list = length(contigs)\n",
      "\tfor item in contig_length_list:\n",
      "\t\tN50_feature_set.append(float(item)/float(N50_value))\n",
      "\n",
      "\n",
      "\treturn N50_feature_set \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "def read_length_features(contigs):\n",
      "\t\n",
      "\tcontig_length_list = length(contigs)\n",
      "\tmax_length = max(contig_length_list)\n",
      "\tmin_length = min(contig_length_list)\n",
      "\tmedian_length = statistics.median(contig_length_list)#Median Length\n",
      "\tlength_features = {}\n",
      "\tlength_features[\"max\"] = max_length \n",
      "\tlength_features[\"min\"] = min_length \n",
      "\tlength_features[\"median\"] = median_length \n",
      "\tlength_features[\"average\"] = float(sum(contig_length_list)) / len(contig_length_list)\n",
      "\n",
      "\treturn length_features \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "def individual_length(contig):\n",
      "\tif (len(contig) == 0):\n",
      "\t\tprint 1\n",
      "\n",
      "\treturn len(contig)\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "if __name__ == '__main__':\n",
      "\n",
      "\n",
      "\t#Storing the data for the contigs in a dictionary \n",
      "\tcontigs = {}\n",
      "\n",
      "\tcounter = 0\n",
      "\tcontig_list = []\n",
      "\t#Parsing the scaffolds generated to store in the dictionary\n",
      "\tfor seq_record in SeqIO.parse(sys.argv[1],\"fasta\"):\n",
      "\t\tcontigs[seq_record.id] = seq_record.seq\n",
      "\t\tcontig_list.append((seq_record.id, seq_record.seq))\n",
      "\t\tif counter < 4:\n",
      "\t\t\tprint (seq_record.id)\n",
      "\t\t\tprint len(seq_record.seq)\n",
      "\t\tcounter +=1\n",
      "\tprint \"-------------------------\"\n",
      "\n",
      "\n",
      "\n",
      "\t#Core Features : \n",
      "\tcontig_core_features = read_length_features(contigs)\n",
      "\n",
      "\n",
      "\n",
      "\tfeat_names = ['Core_length', 'Dev_from_max', 'Dev_from_min', 'Dev_from_avg']\n",
      "\tfeat_names = feat_names+ ['Dev_from_med', 'Dev_from_N50', 'Dev_from_L50']\n",
      "\t# feat_names = feat_names + ['Nb_repeats', 'Avg_rp_exp', 'Avg_rp_period', 'Avg_rp_length', 'Avg_rp_err']\n",
      "\n",
      "\tfeat_df = pd.DataFrame(columns=[\"ID\"] + feat_names)\n",
      "\n",
      "\ttval=0\n",
      "\tfor contig_item in contig_list:\n",
      "\t\ttval+=1\n",
      "\n",
      "\t\tcontig = contig_item[1]\n",
      "\t\t#Initializing a temporary list for features\n",
      "\t\ttemp = []\n",
      "\n",
      "\t\ttemp.append(contig_item[0])\n",
      "\n",
      "\t\t#Feature 1  : Core Length\n",
      "\t\ttemp.append(individual_length(contig))\n",
      "\n",
      "\t\t#Feature 2 : Deviation from max\n",
      "\t\ttemp.append(contig_core_features['max'] - individual_length(contig))\n",
      "\n",
      "\n",
      "\t\t#Feature 3 : Deviation from min\n",
      "\t\ttemp.append(individual_length(contig) - contig_core_features['min'])\n",
      "\n",
      "\n",
      "\t\t#Feature 4 : Deviation from average\n",
      "\t\tavg = average_contig_length(contigs)\n",
      "\t\tdev_from_avg = individual_length(contig) - avg \n",
      "\t\tif dev_from_avg>=0:\n",
      "\t\t\ttemp.append(dev_from_avg)\n",
      "\t\telse:\n",
      "\t\t\ttemp.append(-1*dev_from_avg)\n",
      "\n",
      "\t\t#Feature 5: Deviation from median\n",
      "\t\tdev_from_med = individual_length(contig) - contig_core_features['median']\n",
      "\t\tif dev_from_med>=0:\n",
      "\t\t\ttemp.append(dev_from_med)\n",
      "\t\telse:\n",
      "\t\t\ttemp.append(-1*dev_from_med)\n",
      "\n",
      "\t\t#Feature 6 : Deviation from N50\n",
      "\t\tn50 = N50(contigs)\n",
      "\t\ttemp.append(float(individual_length(contig))/float(n50))\n",
      "\n",
      "\n",
      "\t\t#Feature 7: Deviation from L50\n",
      "\t\tl50 = L50(contigs)\n",
      "\t\ttemp.append(float(individual_length(contig))/float(l50))\n",
      "\n",
      "\n",
      "\t\t#### Repetition Features below ####\n",
      "\n",
      "\t\t# temp_contig_file = open('mreps/tempfile.fa', 'w')\n",
      "\t\t# temp_contig_file.write('>'+contig_item[0] + '\\n')\n",
      "\t\t# temp_contig_file.write(str(contig) )\n",
      "\t\t# temp_contig_file.close()\n",
      "\n",
      "\t\t# mreps_out = subprocess.check_output(['./mreps/mreps','-res', '1', '-exp' ,'3' ,'-fasta', 'mreps/tempfile.fa'])\n",
      "\t\t# line_wise = mreps_out.split('\\n')\n",
      "\t\t\n",
      "\t\t# Avg_rp_exp =0.0\n",
      "\t\t# Avg_rp_period =0.0\n",
      "\t\t# Avg_rp_length =0.0\n",
      "\t\t# Avg_rp_err =0.0\n",
      "\n",
      "\t\t# try:\n",
      "\t\t# \trequired_out = line_wise[6:]\n",
      "\t\t# \tnb_repeats = int(required_out[-1])\n",
      "\t\t# \tmeta_data = required_out[:-1]\n",
      "\t\t# \tnr = len(meta_data)\n",
      "\n",
      "\t\t# \tfor j in meta_data:\n",
      "\t\t# \t\titem = j.split()\n",
      "\t\t# \t\trp_len = int(item[4])\n",
      "\t\t# \t\trp_per = float(item[5][1:-1])\n",
      "\t\t# \t\trp_exp = float(item[6][1:-1])\n",
      "\t\t# \t\trp_err = float(item[7])\n",
      "\t\t\t\t\n",
      "\t\t# \t\tAvg_rp_exp += rp_exp\n",
      "\t\t# \t\tAvg_rp_period += rp_per\n",
      "\t\t# \t\tAvg_rp_length += rp_len\n",
      "\t\t# \t\tAvg_rp_err += rp_err\n",
      "\n",
      "\t\t# \tAvg_rp_exp /= nr\n",
      "\t\t# \tAvg_rp_period /= nr\n",
      "\t\t# \tAvg_rp_length /= nr\n",
      "\t\t# \tAvg_rp_err /= nr\n",
      "\t\t# except:\n",
      "\t\t# \tnb_repeats=0\n",
      "\n",
      "\n",
      "\t\t# temp.append(nb_repeats)\n",
      "\t\t# temp.append(Avg_rp_exp)\n",
      "\t\t# temp.append(Avg_rp_period)\n",
      "\t\t# temp.append(Avg_rp_length)\n",
      "\t\t# temp.append(Avg_rp_err)\n",
      "\t\tif tval<5:\n",
      "\t\t\tprint temp\n",
      "\n",
      "\t\tif tval%400 == 0:\n",
      "\t\t\tprint tval\n",
      "\t\t\tprint(\"--- %s seconds ---\" % (time.time() - start_time))\n",
      "\n",
      "\n",
      "\n",
      "\t\ttemp_df = pd.DataFrame([temp], columns=[\"ID\"] + feat_names)\n",
      "\t\tfeat_df = feat_df.append(temp_df)\n",
      "\n",
      "\t\tif tval == 5000:\n",
      "\t\t\tbreak\n",
      "\n",
      "\n",
      "\t# Writing csv file\n",
      "\tprint feat_df.head()\n",
      "\n",
      "\tfeat_df.to_csv(str(PATH+ sys.argv[1].split('.')[0].split('/')[-1] )+'_all_features.csv', index=None)\n",
      "\n",
      "\n",
      "\n",
      "\t##########################################################\n",
      "\tprint(\"--- %s seconds ---\" % (time.time() - start_time))\n",
      "\tprint \"###############\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}